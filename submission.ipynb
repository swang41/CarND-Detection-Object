{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train Phrase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "import os\n",
    "import glob\n",
    "import time\n",
    "import sklearn\n",
    "import matplotlib.image as mpimg\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from skimage.feature import hog\n",
    "import extract_features\n",
    "import slide_windows\n",
    "from scipy.ndimage.measurements import label\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from collections import deque\n",
    "# Import everything needed to edit/save/watch video clips\n",
    "from moviepy.editor import VideoFileClip\n",
    "from IPython.display import HTML"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Setting up (load data and subset it)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape:  (64, 64, 3)\n",
      "pixel value:  33  -  192\n"
     ]
    }
   ],
   "source": [
    "vehicle_folds = os.listdir('./data/vehicles')\n",
    "non_vehicle_folds = os.listdir('./data/non-vehicles')\n",
    "non_vehicles = []\n",
    "vehicles = []\n",
    "\n",
    "for folder in vehicle_folds:\n",
    "    vehicles.extend(glob.glob('./data/vehicles/' + folder + '/*.png'))\n",
    "\n",
    "for folder in non_vehicle_folds:\n",
    "    non_vehicles.extend(glob.glob('./data/non-vehicles/' + folder + '/*.png'))\n",
    "\n",
    "example = cv2.imread(vehicles[0])\n",
    "print('Shape: ', example.shape)\n",
    "print('pixel value: ', np.min(example), \" - \", np.max(example))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of vehicle image: 8792, Number of non-vehicle image: 8968\n",
      "Number of subset vehicle image: 3000, Number of subset non-vehicle image: 3000\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(123)\n",
    "num_subset = 3000\n",
    "if num_subset == 'ALL':\n",
    "    car_subset = vehicles\n",
    "    notcar_subset = non_vehicles\n",
    "else:\n",
    "    car_subset = np.array(vehicles)[np.random.choice(len(vehicles), num_subset)]\n",
    "    notcar_subset = np.array(non_vehicles)[np.random.choice(len(non_vehicles), num_subset)]\n",
    "\n",
    "print('Number of vehicle image: {0}, Number of non-vehicle image: {1}'.\n",
    "      format(len(vehicles), len(non_vehicles)))\n",
    "print('Number of subset vehicle image: {0}, Number of subset non-vehicle image: {1}'.\n",
    "      format(len(car_subset), len(notcar_subset)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Training model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# hog feature extration\n",
    "hog_params = {'cspace': 'YCrCb',\n",
    "             'orient': 9,\n",
    "             'pix_per_cell': 8,\n",
    "             'cell_per_block': 2,\n",
    "             'hog_channel': 'ALL'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting features took: 35.48 seconds to extract 5292 features\n"
     ]
    }
   ],
   "source": [
    "t = time.time()\n",
    "car_features = extract_features.extract_f(car_subset, \n",
    "                         hog_params)\n",
    "notcar_features = extract_features.extract_f(notcar_subset,  \n",
    "                         hog_params)\n",
    "X = np.vstack((car_features, notcar_features))\n",
    "y = np.hstack((np.ones(len(car_subset)), np.zeros(len(notcar_subset))))\n",
    "print('Extracting features took: {0:.2f} seconds to extract {1} features'.\n",
    "      format(time.time() - t, X.shape[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "rand_state = np.random.randint(0, 100)\n",
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "    X, y, test_size=0.3, random_state=rand_state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "scaler = StandardScaler().fit(X_train)\n",
    "X_train = scaler.transform(X_train)\n",
    "X_val = scaler.transform(X_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def train_model(train, target, val, model, use_pca, use_bagging,\n",
    "               bag_params=None):\n",
    "    if use_pca:\n",
    "        pca = PCA(n_components = 500)\n",
    "        pca.fit(X_train)\n",
    "        print(np.sum(pca.explained_variance_ratio_))\n",
    "        train = pca.transform(train)\n",
    "        val = pca.transform(val)\n",
    "    if use_bagging:\n",
    "        model = BaggingClassifier(base_estimator=model,\n",
    "                                      n_estimators=bag_params['n_estimators'],\n",
    "                                      max_features=bag_params['max_features'],\n",
    "                                      max_samples=bag_params['max_samples'])\n",
    "    model.fit(train, target)\n",
    "    if use_pca:\n",
    "        return model, pca, train, val\n",
    "    else:\n",
    "        return model, train, val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9603067050186835\n"
     ]
    }
   ],
   "source": [
    "use_pca = True\n",
    "use_bagging = True\n",
    "bag_params = {'n_estimators': 10,\n",
    "             'max_features': 0.7,\n",
    "             'max_samples': 0.5}\n",
    "nn = MLPClassifier(hidden_layer_sizes=(50, 10), activation='relu', alpha = 1e-1, solver='adam', early_stopping = True, verbose=False)\n",
    "\n",
    "if use_pca:\n",
    "    model, pca, train, val = train_model(X_train, y_train, X_val, nn, use_pca, use_bagging, bag_params)\n",
    "else:\n",
    "    model, train, val = train_model(X_train, y_train, X_val, nn, use_pca, use_bagging, bag_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training acc: 0.9583\n",
      "Validation acc: 0.9294\n"
     ]
    }
   ],
   "source": [
    "print('Training acc: {0:.4f}'.format(model.score(train, y_train)))\n",
    "print('Validation acc: {0:.4f}'.format(model.score(val, y_val)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test Phrase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def draw_heatmap(heatmap, found):\n",
    "    for box in found:\n",
    "        heatmap[box[0][1]:box[1][1], box[0][0]:box[1][0]] += 1\n",
    "    return heatmap\n",
    "\n",
    "def draw_heatmap_deque(heatmap, d):\n",
    "    for found in d:\n",
    "        for box in found:\n",
    "            heatmap[box[0][1]:box[1][1], box[0][0]:box[1][0]] += 1\n",
    "    return heatmap\n",
    "\n",
    "\n",
    "def threshold(heatmap, thres):\n",
    "    heatmap[heatmap < thres] = 0\n",
    "    return heatmap\n",
    "\n",
    "def draw_labeled_bboxes(image, labels):\n",
    "    # Iterate through all detected cars\n",
    "    image = image.copy()\n",
    "    for car_number in range(1, labels[1]+1):\n",
    "        # Find pixels with each car_number label value\n",
    "        nonzero = (labels[0] == car_number).nonzero()\n",
    "        # Identify x and y values of those pixels\n",
    "        nonzeroy = np.array(nonzero[0])\n",
    "        nonzerox = np.array(nonzero[1])\n",
    "        # Define a bounding box based on min/max x and y\n",
    "        bbox = ((np.min(nonzerox), np.min(nonzeroy)), (np.max(nonzerox), np.max(nonzeroy)))\n",
    "        # Draw the box on the image\n",
    "        cv2.rectangle(image, bbox[0], bbox[1], (0,0,255), 6)\n",
    "    # Return the image\n",
    "    return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def find_cars(img, y_start_stops, x_start_stops, scale, model, scaler, use_pca=True, pca=None,\n",
    "              cells_per_step = 2, hog_params = None):\n",
    "    \n",
    "    ystart, ystop = y_start_stops\n",
    "    xstart, xstop = x_start_stops\n",
    "    \n",
    "    img_tosearch = img[ystart:ystop,xstart:xstop,:]\n",
    "    ctrans_tosearch = img_tosearch\n",
    "    if hog_params['cspace'] != 'RGB':\n",
    "                exec(\"%s = %s\" % ('ctrans_tosearch',\n",
    "                                  'cv2.cvtColor(img_tosearch, cv2.COLOR_RGB2' + hog_params['cspace'] + ')')) \n",
    "    if scale != 1:\n",
    "        imshape = ctrans_tosearch.shape\n",
    "        ctrans_tosearch = cv2.resize(ctrans_tosearch, (np.int(imshape[1]/scale), np.int(imshape[0]/scale)))\n",
    "        \n",
    "    ch1 = ctrans_tosearch[:,:,0]\n",
    "    ch2 = ctrans_tosearch[:,:,1]\n",
    "    ch3 = ctrans_tosearch[:,:,2]\n",
    "\n",
    "    # Define blocks and steps as above\n",
    "    nxblocks = (ch1.shape[1] // hog_params['pix_per_cell']) - hog_params['cell_per_block'] + 1\n",
    "    nyblocks = (ch1.shape[0] // hog_params['pix_per_cell']) - hog_params['cell_per_block'] + 1 \n",
    "    nfeat_per_block = hog_params['orient']*hog_params['cell_per_block']**2\n",
    "    \n",
    "    # 64 was the orginal sampling rate, with 8 cells and 8 pix per cell\n",
    "    window = 64\n",
    "    nblocks_per_window = (window // hog_params['pix_per_cell']) - hog_params['cell_per_block'] + 1\n",
    "    cells_per_step = 2  # Instead of overlap, define how many cells to step\n",
    "    nxsteps = (nxblocks - nblocks_per_window) // cells_per_step + 1\n",
    "    nysteps = (nyblocks - nblocks_per_window) // cells_per_step + 1\n",
    "    \n",
    "    # Compute individual channel HOG features for the entire image\n",
    "    hog1 = extract_features.get_hog_features(ch1,\n",
    "                            hog_params['orient'],\n",
    "                            hog_params['pix_per_cell'],\n",
    "                            hog_params['cell_per_block'],\n",
    "                            feature_vec=False)\n",
    "    hog2 = extract_features.get_hog_features(ch2,\n",
    "                            hog_params['orient'],\n",
    "                            hog_params['pix_per_cell'],\n",
    "                            hog_params['cell_per_block'],\n",
    "                            feature_vec=False)\n",
    "    hog3 = extract_features.get_hog_features(ch3,\n",
    "                            hog_params['orient'],\n",
    "                            hog_params['pix_per_cell'],\n",
    "                            hog_params['cell_per_block'],\n",
    "                            feature_vec=False)\n",
    "    \n",
    "    found = []\n",
    "    for xb in range(nxsteps):\n",
    "        for yb in range(nysteps):\n",
    "            ypos = yb*cells_per_step\n",
    "            xpos = xb*cells_per_step\n",
    "            # Extract HOG for this patch\n",
    "            hog_feat1 = hog1[ypos:ypos+nblocks_per_window, xpos:xpos+nblocks_per_window].ravel() \n",
    "            hog_feat2 = hog2[ypos:ypos+nblocks_per_window, xpos:xpos+nblocks_per_window].ravel() \n",
    "            hog_feat3 = hog3[ypos:ypos+nblocks_per_window, xpos:xpos+nblocks_per_window].ravel() \n",
    "            hog_features = np.hstack((hog_feat1, hog_feat2, hog_feat3))\n",
    "\n",
    "            xleft = xpos*hog_params['pix_per_cell']\n",
    "            ytop = ypos*hog_params['pix_per_cell']\n",
    "            \n",
    "            # Scale features and make a prediction\n",
    "            test_features = scaler.transform(hog_features).reshape(1, -1)    \n",
    "\n",
    "            if use_pca:\n",
    "                test_features = pca.transform(test_features)\n",
    "            \n",
    "            pred = 1 if model.predict_proba(test_features)[:,1] > prob else 0\n",
    "            \n",
    "            if pred == 1:\n",
    "                xbox_left = np.int(xleft*scale)\n",
    "                ytop_draw = np.int(ytop*scale)\n",
    "                win_draw = np.int(window*scale)\n",
    "                box = ((xbox_left+xstart, ytop_draw+ystart),(xbox_left+win_draw+xstart,ytop_draw+win_draw+ystart)) \n",
    "                found.append(box)\n",
    "    return found"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def process_image(image):\n",
    "    \n",
    "    found = []\n",
    "    \n",
    "    for scale in scales:\n",
    "        found.extend(find_cars(image, y_start_stops, x_start_stops, scale,\n",
    "                      model, scaler, use_pca, pca, cells_per_step, hog_params))\n",
    "    #print(len(found))\n",
    "    \n",
    "    d.append(found)\n",
    "    \n",
    "    heatmap = np.zeros((image.shape[0:2]))\n",
    "    heatmap = draw_heatmap_deque(heatmap, d)\n",
    "    headmap = threshold(heatmap, threshold_pixel)\n",
    "\n",
    "    labels = label(heatmap)\n",
    "\n",
    "    window_img = draw_labeled_bboxes(image, labels)\n",
    "\n",
    "    #window_img = slide_windows.draw_boxes(image, found, color=(0, 0, 255), thick=6) \n",
    "    \n",
    "    return window_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_clip = VideoFileClip(\"./test_video.mp4\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[MoviePy] >>>> Building video ./out_test_clip.mp4\n",
      "[MoviePy] Writing video ./out_test_clip.mp4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 97%|███████████████████████████████████████████████████████████████████████████████▉  | 38/39 [03:40<00:05,  5.80s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[MoviePy] Done.\n",
      "[MoviePy] >>>> Video ready: ./out_test_clip.mp4 \n",
      "\n",
      "Wall time: 3min 41s\n"
     ]
    }
   ],
   "source": [
    "scales = [1.25, 1.5]\n",
    "y_start_stops = (380, 700)\n",
    "x_start_stops = (780, 1280)\n",
    "cells_per_step = 2\n",
    "prob = 0.8\n",
    "threshold_pixel = 4\n",
    "d = deque(maxlen=5)\n",
    "\n",
    "out_clip = test_clip.fl_image(process_image)\n",
    "output = './out_test_clip.mp4'\n",
    "%time out_clip.write_videofile(output, audio=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<video width=\"960\" height=\"540\" controls>\n",
       "  <source src=\"./out_test_clip.mp4\">\n",
       "</video>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "HTML(\"\"\"\n",
    "<video width=\"960\" height=\"540\" controls>\n",
    "  <source src=\"{0}\">\n",
    "</video>\n",
    "\"\"\".format(output))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "clip25 = VideoFileClip(\"./project_video_lane_finding.mp4\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[MoviePy] >>>> Building video ./out_clip_25_multi.mp4\n",
      "[MoviePy] Writing video ./out_clip_25_multi.mp4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████▉| 1260/1261 [2:11:20<00:06,  6.21s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[MoviePy] Done.\n",
      "[MoviePy] >>>> Video ready: ./out_clip_25_multi.mp4 \n",
      "\n",
      "Wall time: 2h 11min 20s\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "scales = [1.25, 1.5]\n",
    "y_start_stops = (380, 700)\n",
    "x_start_stops = (750, 1280)\n",
    "cells_per_step = 2\n",
    "prob = 0.8\n",
    "threshold_pixel = 4\n",
    "d = deque(maxlen=5)\n",
    "\n",
    "out_clip_25_multi = clip25.fl_image(process_image)\n",
    "output_25 = './out_clip_25_multi.mp4'\n",
    "%time out_clip_25_multi.write_videofile(output_25, audio=False)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<video width=\"960\" height=\"540\" controls>\n",
       "  <source src=\"./out_clip_25_multi.mp4\">\n",
       "</video>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "HTML(\"\"\"\n",
    "<video width=\"960\" height=\"540\" controls>\n",
    "  <source src=\"{0}\">\n",
    "</video>\n",
    "\"\"\".format(output_25))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
